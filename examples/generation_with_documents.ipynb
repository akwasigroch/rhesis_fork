{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3789e83",
   "metadata": {},
   "source": [
    "## DocumentSynthesizer example (with ContextGenerator)\n",
    "\n",
    "This notebook demonstrates how to use the refactored `DocumentSynthesizer` that:\n",
    "- Extracts text from documents\n",
    "- Generates prompt-ready contexts using `ContextGenerator` (semantic chunking, markdown-aware)\n",
    "- Delegates test generation to `PromptSynthesizer`, per-context\n",
    "\n",
    "You can configure:\n",
    "\n",
    "Initialization Parameters (when creating the synthesizer):\n",
    "- `prompt`: Generation prompt for test cases (required)\n",
    "- `batch_size`: Maximum tests per LLM call (optional)\n",
    "- `system_prompt`: Custom system prompt template (optional)\n",
    "- `max_context_tokens`: Token limit per context (default: 1000)\n",
    "- `strategy`: Context selection strategy - \"sequential\" or \"random\" (default: \"random\")\n",
    "\n",
    "Generation Parameters (when calling .generate()):\n",
    "- `documents`: List of document dictionaries (required for document-based generation)\n",
    "  Each document should contain:\n",
    "  - `name` (str): Document identifier/filename\n",
    "  - `description` (str): Brief description of document content\n",
    "  - `path` (str): File path to document OR\n",
    "  - `content` (str): Raw text content (if provided, overrides path)\n",
    "- `num_tests`: Total number of tests to generate across all contexts (default: 5)\n",
    "- `tests_per_context`: Target tests per context - caps total at num_tests (optional)\n",
    "\n",
    "Each generated test includes metadata mapping it back to its source context and documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea59c03",
   "metadata": {},
   "source": [
    "### Example 1: Using direct content (no file paths needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhesis.sdk.synthesizers.document_synthesizer import DocumentSynthesizer\n",
    "from rhesis.sdk.types import Document\n",
    "\n",
    "\n",
    "prompt = \"Generate diverse test cases for insurance claims handling.\"\n",
    "\n",
    "doc_synth = DocumentSynthesizer(\n",
    "    prompt=prompt, \n",
    ")\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        name=\"policy_terms.md\",\n",
    "        description=\"Insurance policy terms and coverage\",\n",
    "        content=\"\"\"\n",
    "# Insurance Policy Terms\n",
    "\n",
    "## Coverage\n",
    "- Medical emergencies\n",
    "- Theft and loss\n",
    "\n",
    "## Exclusions\n",
    "- Intentional damage\n",
    "- Pre-existing conditions\n",
    "\n",
    "---\n",
    "\n",
    "## Claims Process\n",
    "1. Report incident within 48 hours\n",
    "2. Provide documentation\n",
    "3. Await assessment\n",
    "        \"\"\",\n",
    "    ),\n",
    "    Document(\n",
    "        name=\"claims_guidelines.md\",\n",
    "        description=\"Guidelines for handling claims\",\n",
    "        content=\"\"\"\n",
    "# Claims Handling Guidelines\n",
    "\n",
    "Claims should be processed within 14 days. Fraud indicators include inconsistent dates and unverifiable receipts.\n",
    "        \"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "result = doc_synth.generate(documents=documents, num_tests=10)\n",
    "\n",
    "len(result.tests), result.metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first test and its enhanced metadata\n",
    "first = result.tests[0]\n",
    "{\n",
    "  \"prompt\": first[\"prompt\"][\"content\"],\n",
    "  \"behavior\": first[\"behavior\"],\n",
    "  \"category\": first[\"category\"],\n",
    "  \"topic\": first[\"topic\"],\n",
    "  \"metadata_keys\": list(first[\"metadata\"].keys()),\n",
    "  \"context_index\": first[\"metadata\"][\"context_index\"],\n",
    "  \"context_length\": first[\"metadata\"][\"context_length\"],\n",
    "  \"source_document\": first[\"metadata\"][\"sources\"][0][\"source\"],\n",
    "  \"source_name\": first[\"metadata\"][\"sources\"][0][\"name\"],\n",
    "  \"source_description\": first[\"metadata\"][\"sources\"][0][\"description\"],\n",
    "  \"context_preview\": first[\"metadata\"][\"sources\"][0][\"content\"][:160] + \"...\",\n",
    "  \"generated_by\": first[\"metadata\"][\"generated_by\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a00af7e",
   "metadata": {},
   "source": [
    "### Example 2: Using file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"/Users/emanuelederossi/Downloads/15227EN_MV_GIC_10.2021 copia 2.pdf\"\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "    name=\"Sample Document\", description=\"Example document for testing\", path=doc_path)\n",
    "]\n",
    "\n",
    "prompt = \"Generate test cases about this document to check if the information is correct. Always say: given that the document says: (literal content of the document), why ...\"\n",
    "\n",
    "doc_synth = DocumentSynthesizer(\n",
    "    prompt=prompt, \n",
    "    max_context_tokens=1500,\n",
    ")\n",
    "\n",
    "result = doc_synth.generate(documents=documents, num_tests=10)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first test and its enhanced metadata\n",
    "first = result.tests[0]\n",
    "{\n",
    "  \"prompt\": first[\"prompt\"][\"content\"],\n",
    "  \"behavior\": first[\"behavior\"],\n",
    "  \"category\": first[\"category\"],\n",
    "  \"topic\": first[\"topic\"],\n",
    "  \"metadata_keys\": list(first[\"metadata\"].keys()),\n",
    "  \"context_index\": first[\"metadata\"][\"context_index\"],\n",
    "  \"context_length\": first[\"metadata\"][\"context_length\"],\n",
    "  \"source_document\": first[\"metadata\"][\"sources\"][0][\"source\"],\n",
    "  \"source_name\": first[\"metadata\"][\"sources\"][0][\"name\"],\n",
    "  \"source_description\": first[\"metadata\"][\"sources\"][0][\"description\"],\n",
    "  \"context_preview\": first[\"metadata\"][\"sources\"][0][\"content\"][:160] + \"...\",\n",
    "  \"generated_by\": first[\"metadata\"][\"generated_by\"],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
